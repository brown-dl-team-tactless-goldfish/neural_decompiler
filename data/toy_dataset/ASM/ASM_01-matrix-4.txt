func_1:
        pushq   %rbp
        movq    %rsp, %rbp
        movq    %rdi, -8(%rbp)
        movl    %esi, -12(%rbp)
        movl    %edx, -16(%rbp)
        movl    %ecx, -20(%rbp)
        movl    %r8d, -24(%rbp)
        movq    %r9, -32(%rbp)
        cmpl    $0, -20(%rbp)
        jle     .L2
        movl    -20(%rbp), %eax
        cltq
        salq    $3, %rax
        leaq    -8(%rax), %rdx
        movq    -8(%rbp), %rax
        addq    %rdx, %rax
        movq    (%rax), %rax
        movl    -24(%rbp), %edx
        movslq  %edx, %rdx
        salq    $2, %rdx
        addq    %rdx, %rax
        movl    (%rax), %eax
        testl   %eax, %eax
        jns     .L2
        movq    16(%rbp), %rax
        movl    (%rax), %eax
        leal    1(%rax), %edx
        movq    16(%rbp), %rax
        movl    %edx, (%rax)
        movq    16(%rbp), %rax
        movl    (%rax), %eax
        cltq
        leaq    0(,%rax,8), %rdx
        movq    -32(%rbp), %rax
        addq    %rdx, %rax
        movl    -20(%rbp), %edx
        subl    $1, %edx
        movl    %edx, (%rax)
        movq    16(%rbp), %rax
        movl    (%rax), %eax
        cltq
        leaq    0(,%rax,8), %rdx
        movq    -32(%rbp), %rax
        addq    %rax, %rdx
        movl    -24(%rbp), %eax
        movl    %eax, 4(%rdx)
        movl    -20(%rbp), %eax
        cltq
        salq    $3, %rax
        leaq    -8(%rax), %rdx
        movq    -8(%rbp), %rax
        addq    %rdx, %rax
        movq    (%rax), %rax
        movl    -24(%rbp), %edx
        movslq  %edx, %rdx
        salq    $2, %rdx
        addq    %rax, %rdx
        movl    24(%rbp), %eax
        movl    %eax, (%rdx)
.L2:
        movl    -20(%rbp), %eax
        addl    $1, %eax
        cmpl    %eax, -12(%rbp)
        jle     .L3
        movl    -20(%rbp), %eax
        cltq
        addq    $1, %rax
        leaq    0(,%rax,8), %rdx
        movq    -8(%rbp), %rax
        addq    %rdx, %rax
        movq    (%rax), %rax
        movl    -24(%rbp), %edx
        movslq  %edx, %rdx
        salq    $2, %rdx
        addq    %rdx, %rax
        movl    (%rax), %eax
        testl   %eax, %eax
        jns     .L3
        movq    16(%rbp), %rax
        movl    (%rax), %eax
        leal    1(%rax), %edx
        movq    16(%rbp), %rax
        movl    %edx, (%rax)
        movq    16(%rbp), %rax
        movl    (%rax), %eax
        cltq
        leaq    0(,%rax,8), %rdx
        movq    -32(%rbp), %rax
        addq    %rdx, %rax
        movl    -20(%rbp), %edx
        addl    $1, %edx
        movl    %edx, (%rax)
        movq    16(%rbp), %rax
        movl    (%rax), %eax
        cltq
        leaq    0(,%rax,8), %rdx
        movq    -32(%rbp), %rax
        addq    %rax, %rdx
        movl    -24(%rbp), %eax
        movl    %eax, 4(%rdx)
        movl    -20(%rbp), %eax
        cltq
        addq    $1, %rax
        leaq    0(,%rax,8), %rdx
        movq    -8(%rbp), %rax
        addq    %rdx, %rax
        movq    (%rax), %rax
        movl    -24(%rbp), %edx
        movslq  %edx, %rdx
        salq    $2, %rdx
        addq    %rax, %rdx
        movl    24(%rbp), %eax
        movl    %eax, (%rdx)
.L3:
        cmpl    $0, -24(%rbp)
        jle     .L4
        movl    -20(%rbp), %eax
        cltq
        leaq    0(,%rax,8), %rdx
        movq    -8(%rbp), %rax
        addq    %rdx, %rax
        movq    (%rax), %rax
        movl    -24(%rbp), %edx
        movslq  %edx, %rdx
        salq    $2, %rdx
        subq    $4, %rdx
        addq    %rdx, %rax
        movl    (%rax), %eax
        testl   %eax, %eax
        jns     .L4
        movq    16(%rbp), %rax
        movl    (%rax), %eax
        leal    1(%rax), %edx
        movq    16(%rbp), %rax
        movl    %edx, (%rax)
        movq    16(%rbp), %rax
        movl    (%rax), %eax
        cltq
        leaq    0(,%rax,8), %rdx
        movq    -32(%rbp), %rax
        addq    %rax, %rdx
        movl    -20(%rbp), %eax
        movl    %eax, (%rdx)
        movq    16(%rbp), %rax
        movl    (%rax), %eax
        cltq
        leaq    0(,%rax,8), %rdx
        movq    -32(%rbp), %rax
        addq    %rdx, %rax
        movl    -24(%rbp), %edx
        subl    $1, %edx
        movl    %edx, 4(%rax)
        movl    -20(%rbp), %eax
        cltq
        leaq    0(,%rax,8), %rdx
        movq    -8(%rbp), %rax
        addq    %rdx, %rax
        movq    (%rax), %rax
        movl    -24(%rbp), %edx
        movslq  %edx, %rdx
        salq    $2, %rdx
        subq    $4, %rdx
        addq    %rax, %rdx
        movl    24(%rbp), %eax
        movl    %eax, (%rdx)
.L4:
        movl    -24(%rbp), %eax
        addl    $1, %eax
        cmpl    %eax, -16(%rbp)
        jle     .L6
        movl    -20(%rbp), %eax
        cltq
        leaq    0(,%rax,8), %rdx
        movq    -8(%rbp), %rax
        addq    %rdx, %rax
        movq    (%rax), %rax
        movl    -24(%rbp), %edx
        movslq  %edx, %rdx
        addq    $1, %rdx
        salq    $2, %rdx
        addq    %rdx, %rax
        movl    (%rax), %eax
        testl   %eax, %eax
        jns     .L6
        movq    16(%rbp), %rax
        movl    (%rax), %eax
        leal    1(%rax), %edx
        movq    16(%rbp), %rax
        movl    %edx, (%rax)
        movq    16(%rbp), %rax
        movl    (%rax), %eax
        cltq
        leaq    0(,%rax,8), %rdx
        movq    -32(%rbp), %rax
        addq    %rax, %rdx
        movl    -20(%rbp), %eax
        movl    %eax, (%rdx)
        movq    16(%rbp), %rax
        movl    (%rax), %eax
        cltq
        leaq    0(,%rax,8), %rdx
        movq    -32(%rbp), %rax
        addq    %rdx, %rax
        movl    -24(%rbp), %edx
        addl    $1, %edx
        movl    %edx, 4(%rax)
        movl    -20(%rbp), %eax
        cltq
        leaq    0(,%rax,8), %rdx
        movq    -8(%rbp), %rax
        addq    %rdx, %rax
        movq    (%rax), %rax
        movl    -24(%rbp), %edx
        movslq  %edx, %rdx
        addq    $1, %rdx
        salq    $2, %rdx
        addq    %rax, %rdx
        movl    24(%rbp), %eax
        movl    %eax, (%rdx)
.L6:
        nop
        popq    %rbp
        ret
func_2:
        pushq   %rbp
        movq    %rsp, %rbp
        pushq   %rbx
        subq    $120, %rsp
        movq    %rdi, -88(%rbp)
        movl    %esi, -92(%rbp)
        movq    %rdx, -104(%rbp)
        movq    %rcx, -112(%rbp)
        movq    %r8, -120(%rbp)
        movq    -104(%rbp), %rax
        movl    (%rax), %eax
        movl    %eax, -40(%rbp)
        movl    -92(%rbp), %eax
        movl    %eax, -44(%rbp)
        movl    -44(%rbp), %eax
        cltq
        salq    $3, %rax
        movq    %rax, %rdi
        call    malloc
        movq    %rax, -56(%rbp)
        movl    $0, -20(%rbp)
        jmp     .L8
.L9:
        movl    -40(%rbp), %eax
        cltq
        salq    $2, %rax
        movl    -20(%rbp), %edx
        movslq  %edx, %rdx
        leaq    0(,%rdx,8), %rcx
        movq    -56(%rbp), %rdx
        leaq    (%rcx,%rdx), %rbx
        movq    %rax, %rdi
        call    malloc
        movq    %rax, (%rbx)
        movl    -40(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rdx
        movl    -20(%rbp), %eax
        cltq
        leaq    0(,%rax,8), %rcx
        movq    -56(%rbp), %rax
        addq    %rcx, %rax
        movq    (%rax), %rax
        movl    $255, %esi
        movq    %rax, %rdi
        call    memset
        addl    $1, -20(%rbp)
.L8:
        movl    -20(%rbp), %eax
        cmpl    -44(%rbp), %eax
        jl      .L9
        movl    $320000, %edi
        call    malloc
        movq    %rax, -64(%rbp)
        movl    $-1, -72(%rbp)
        movl    $-1, -28(%rbp)
        movl    $1, -32(%rbp)
        movl    $0, -20(%rbp)
        jmp     .L10
.L14:
        movl    $0, -24(%rbp)
        jmp     .L11
.L13:
        movl    -20(%rbp), %eax
        cltq
        leaq    0(,%rax,8), %rdx
        movq    -88(%rbp), %rax
        addq    %rdx, %rax
        movq    (%rax), %rax
        movl    -24(%rbp), %edx
        movslq  %edx, %rdx
        salq    $2, %rdx
        addq    %rdx, %rax
        movl    (%rax), %eax
        testl   %eax, %eax
        jne     .L12
        movl    -20(%rbp), %eax
        cltq
        leaq    0(,%rax,8), %rdx
        movq    -56(%rbp), %rax
        addq    %rdx, %rax
        movq    (%rax), %rax
        movl    -24(%rbp), %edx
        movslq  %edx, %rdx
        salq    $2, %rdx
        addq    %rdx, %rax
        movl    $0, (%rax)
        movq    -64(%rbp), %r9
        movl    -24(%rbp), %r8d
        movl    -20(%rbp), %ecx
        movl    -40(%rbp), %edx
        movl    -44(%rbp), %esi
        movq    -56(%rbp), %rax
        movl    -32(%rbp), %edi
        pushq   %rdi
        leaq    -72(%rbp), %rdi
        pushq   %rdi
        movq    %rax, %rdi
        call    func_1
        addq    $16, %rsp
.L12:
        addl    $1, -24(%rbp)
.L11:
        movl    -24(%rbp), %eax
        cmpl    -40(%rbp), %eax
        jl      .L13
        addl    $1, -20(%rbp)
.L10:
        movl    -20(%rbp), %eax
        cmpl    -44(%rbp), %eax
        jl      .L14
        jmp     .L15
.L18:
        addl    $1, -32(%rbp)
        movl    -72(%rbp), %eax
        movl    %eax, -68(%rbp)
        movl    -28(%rbp), %eax
        movl    %eax, -36(%rbp)
        jmp     .L16
.L17:
        movl    -36(%rbp), %eax
        cltq
        leaq    0(,%rax,8), %rdx
        movq    -64(%rbp), %rax
        addq    %rdx, %rax
        movl    4(%rax), %r8d
        movl    -36(%rbp), %eax
        cltq
        leaq    0(,%rax,8), %rdx
        movq    -64(%rbp), %rax
        addq    %rdx, %rax
        movl    (%rax), %ecx
        movq    -64(%rbp), %r9
        movl    -40(%rbp), %edx
        movl    -44(%rbp), %esi
        movq    -56(%rbp), %rax
        movl    -32(%rbp), %edi
        pushq   %rdi
        leaq    -72(%rbp), %rdi
        pushq   %rdi
        movq    %rax, %rdi
        call    func_1
        addq    $16, %rsp
.L16:
        addl    $1, -36(%rbp)
        movl    -36(%rbp), %eax
        cmpl    -68(%rbp), %eax
        jle     .L17
        movl    -68(%rbp), %eax
        movl    %eax, -28(%rbp)
.L15:
        movl    -72(%rbp), %eax
        cmpl    %eax, -28(%rbp)
        jl      .L18
        movq    -112(%rbp), %rax
        movl    -92(%rbp), %edx
        movl    %edx, (%rax)
        movq    -120(%rbp), %rax
        movq    -104(%rbp), %rdx
        movq    %rdx, (%rax)
        movq    -56(%rbp), %rax
        movq    -8(%rbp), %rbx
        leave
        ret
