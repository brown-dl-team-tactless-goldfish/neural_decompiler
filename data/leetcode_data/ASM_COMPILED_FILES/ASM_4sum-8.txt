func_1:
        pushq   %rbp
        movq    %rsp, %rbp
        movq    %rdi, -8(%rbp)
        movq    %rsi, -16(%rbp)
        movq    -8(%rbp), %rax
        movl    (%rax), %edx
        movq    -16(%rbp), %rax
        movl    (%rax), %eax
        subl    %eax, %edx
        movl    %edx, %eax
        popq    %rbp
        ret
func_2:
        pushq   %rbp
        movq    %rsp, %rbp
        pushq   %rbx
        subq    $72, %rsp
        movq    %rdi, -56(%rbp)
        movl    %esi, -60(%rbp)
        movl    %edx, -64(%rbp)
        movq    %rcx, -72(%rbp)
        movq    $0, -40(%rbp)
        movq    -72(%rbp), %rax
        movl    $0, (%rax)
        cmpq    $0, -56(%rbp)
        je      .L4
        cmpl    $3, -60(%rbp)
        jg      .L5
.L4:
        movl    $0, %eax
        jmp     .L6
.L5:
        movl    -60(%rbp), %eax
        movslq  %eax, %rsi
        movq    -56(%rbp), %rax
        movl    $func_1, %ecx
        movl    $4, %edx
        movq    %rax, %rdi
        call    qsort
        movl    -60(%rbp), %eax
        movslq  %eax, %rdx
        movl    -60(%rbp), %eax
        subl    $1, %eax
        cltq
        imulq   %rax, %rdx
        movl    -60(%rbp), %eax
        subl    $2, %eax
        cltq
        imulq   %rax, %rdx
        movl    -60(%rbp), %eax
        subl    $3, %eax
        cltq
        imulq   %rdx, %rax
        salq    $3, %rax
        movabsq $-6148914691236517205, %rdx
        mulq    %rdx
        movq    %rdx, %rax
        shrq    $4, %rax
        movq    %rax, %rdi
        call    malloc
        movq    %rax, -40(%rbp)
        movl    $0, -20(%rbp)
        jmp     .L7
.L26:
        movl    -20(%rbp), %eax
        addl    $1, %eax
        movl    %eax, -24(%rbp)
        jmp     .L8
.L22:
        movl    -24(%rbp), %eax
        addl    $1, %eax
        movl    %eax, -28(%rbp)
        movl    -60(%rbp), %eax
        subl    $1, %eax
        movl    %eax, -32(%rbp)
        jmp     .L9
.L18:
        movl    -20(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rdx
        movq    -56(%rbp), %rax
        addq    %rdx, %rax
        movl    (%rax), %edx
        movl    -24(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rcx
        movq    -56(%rbp), %rax
        addq    %rcx, %rax
        movl    (%rax), %eax
        addl    %eax, %edx
        movl    -28(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rcx
        movq    -56(%rbp), %rax
        addq    %rcx, %rax
        movl    (%rax), %eax
        addl    %eax, %edx
        movl    -32(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rcx
        movq    -56(%rbp), %rax
        addq    %rcx, %rax
        movl    (%rax), %eax
        addl    %edx, %eax
        movl    %eax, -44(%rbp)
        movl    -44(%rbp), %eax
        cmpl    -64(%rbp), %eax
        jne     .L10
        movq    -72(%rbp), %rax
        movl    (%rax), %eax
        cltq
        leaq    0(,%rax,8), %rdx
        movq    -40(%rbp), %rax
        leaq    (%rdx,%rax), %rbx
        movl    $16, %edi
        call    malloc
        movq    %rax, (%rbx)
        movl    -20(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rdx
        movq    -56(%rbp), %rax
        addq    %rax, %rdx
        movq    -72(%rbp), %rax
        movl    (%rax), %eax
        cltq
        leaq    0(,%rax,8), %rcx
        movq    -40(%rbp), %rax
        addq    %rcx, %rax
        movq    (%rax), %rax
        movl    (%rdx), %edx
        movl    %edx, (%rax)
        movl    -24(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rdx
        movq    -56(%rbp), %rax
        leaq    (%rdx,%rax), %rcx
        movq    -72(%rbp), %rax
        movl    (%rax), %eax
        cltq
        leaq    0(,%rax,8), %rdx
        movq    -40(%rbp), %rax
        addq    %rdx, %rax
        movq    (%rax), %rax
        leaq    4(%rax), %rdx
        movl    (%rcx), %eax
        movl    %eax, (%rdx)
        movl    -28(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rdx
        movq    -56(%rbp), %rax
        leaq    (%rdx,%rax), %rcx
        movq    -72(%rbp), %rax
        movl    (%rax), %eax
        cltq
        leaq    0(,%rax,8), %rdx
        movq    -40(%rbp), %rax
        addq    %rdx, %rax
        movq    (%rax), %rax
        leaq    8(%rax), %rdx
        movl    (%rcx), %eax
        movl    %eax, (%rdx)
        movl    -32(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rdx
        movq    -56(%rbp), %rax
        leaq    (%rdx,%rax), %rcx
        movq    -72(%rbp), %rax
        movl    (%rax), %eax
        cltq
        leaq    0(,%rax,8), %rdx
        movq    -40(%rbp), %rax
        addq    %rdx, %rax
        movq    (%rax), %rax
        leaq    12(%rax), %rdx
        movl    (%rcx), %eax
        movl    %eax, (%rdx)
        movq    -72(%rbp), %rax
        movl    (%rax), %eax
        leal    1(%rax), %edx
        movq    -72(%rbp), %rax
        movl    %edx, (%rax)
        jmp     .L11
.L13:
        addl    $1, -28(%rbp)
.L11:
        movl    -28(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rdx
        movq    -56(%rbp), %rax
        addq    %rdx, %rax
        movl    (%rax), %edx
        movl    -28(%rbp), %eax
        cltq
        addq    $1, %rax
        leaq    0(,%rax,4), %rcx
        movq    -56(%rbp), %rax
        addq    %rcx, %rax
        movl    (%rax), %eax
        cmpl    %eax, %edx
        jne     .L14
        movl    -28(%rbp), %eax
        cmpl    -60(%rbp), %eax
        jl      .L13
        jmp     .L14
.L16:
        subl    $1, -32(%rbp)
.L14:
        movl    -32(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rdx
        movq    -56(%rbp), %rax
        addq    %rdx, %rax
        movl    (%rax), %edx
        movl    -32(%rbp), %eax
        cltq
        salq    $2, %rax
        leaq    -4(%rax), %rcx
        movq    -56(%rbp), %rax
        addq    %rcx, %rax
        movl    (%rax), %eax
        cmpl    %eax, %edx
        jne     .L15
        cmpl    $0, -32(%rbp)
        jg      .L16
.L15:
        addl    $1, -28(%rbp)
        subl    $1, -32(%rbp)
        jmp     .L9
.L10:
        movl    -44(%rbp), %eax
        cmpl    -64(%rbp), %eax
        jle     .L17
        subl    $1, -32(%rbp)
        jmp     .L9
.L17:
        addl    $1, -28(%rbp)
.L9:
        movl    -28(%rbp), %eax
        cmpl    -32(%rbp), %eax
        jl      .L18
        jmp     .L19
.L21:
        addl    $1, -24(%rbp)
.L19:
        movl    -24(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rdx
        movq    -56(%rbp), %rax
        addq    %rdx, %rax
        movl    (%rax), %edx
        movl    -24(%rbp), %eax
        cltq
        addq    $1, %rax
        leaq    0(,%rax,4), %rcx
        movq    -56(%rbp), %rax
        addq    %rcx, %rax
        movl    (%rax), %eax
        cmpl    %eax, %edx
        jne     .L20
        movl    -24(%rbp), %eax
        cmpl    -60(%rbp), %eax
        jl      .L21
.L20:
        addl    $1, -24(%rbp)
.L8:
        movl    -24(%rbp), %eax
        cmpl    -60(%rbp), %eax
        jl      .L22
        jmp     .L23
.L25:
        addl    $1, -20(%rbp)
.L23:
        movl    -20(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rdx
        movq    -56(%rbp), %rax
        addq    %rdx, %rax
        movl    (%rax), %edx
        movl    -20(%rbp), %eax
        cltq
        addq    $1, %rax
        leaq    0(,%rax,4), %rcx
        movq    -56(%rbp), %rax
        addq    %rcx, %rax
        movl    (%rax), %eax
        cmpl    %eax, %edx
        jne     .L24
        movl    -20(%rbp), %eax
        cmpl    -60(%rbp), %eax
        jl      .L25
.L24:
        addl    $1, -20(%rbp)
.L7:
        movl    -20(%rbp), %eax
        cmpl    -60(%rbp), %eax
        jl      .L26
        movq    -40(%rbp), %rax
.L6:
        addq    $72, %rsp
        popq    %rbx
        popq    %rbp
        ret
