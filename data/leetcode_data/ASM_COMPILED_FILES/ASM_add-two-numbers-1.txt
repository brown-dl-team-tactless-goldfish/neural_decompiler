func_1:
        pushq   %rbp
        movq    %rsp, %rbp
        subq    $48, %rsp
        movq    %rdi, -40(%rbp)
        movq    %rsi, -48(%rbp)
        movl    $16, %edi
        call    malloc
        movq    %rax, -24(%rbp)
        movq    -40(%rbp), %rax
        movl    (%rax), %edx
        movq    -48(%rbp), %rax
        movl    (%rax), %eax
        leal    (%rdx,%rax), %ecx
        movl    $1717986919, %edx
        movl    %ecx, %eax
        imull   %edx
        sarl    $2, %edx
        movl    %ecx, %eax
        sarl    $31, %eax
        subl    %eax, %edx
        movl    %edx, %eax
        sall    $2, %eax
        addl    %edx, %eax
        addl    %eax, %eax
        subl    %eax, %ecx
        movl    %ecx, %edx
        movq    -24(%rbp), %rax
        movl    %edx, (%rax)
        movq    -24(%rbp), %rax
        movq    $0, 8(%rax)
        movq    -40(%rbp), %rax
        movl    (%rax), %edx
        movq    -48(%rbp), %rax
        movl    (%rax), %eax
        leal    (%rdx,%rax), %ecx
        movl    $1717986919, %edx
        movl    %ecx, %eax
        imull   %edx
        sarl    $2, %edx
        movl    %ecx, %eax
        sarl    $31, %eax
        subl    %eax, %edx
        movl    %edx, %eax
        movl    %eax, -4(%rbp)
        movl    $16, %edi
        call    malloc
        movq    %rax, -16(%rbp)
        movq    -24(%rbp), %rax
        movq    %rax, -16(%rbp)
        jmp     .L2
.L4:
        movq    -40(%rbp), %rax
        movq    8(%rax), %rax
        movl    (%rax), %edx
        movq    -48(%rbp), %rax
        movq    8(%rax), %rax
        movl    (%rax), %eax
        addl    %eax, %edx
        movl    -4(%rbp), %eax
        addl    %edx, %eax
        movl    %eax, -28(%rbp)
        movl    $16, %edi
        call    malloc
        movq    %rax, %rdx
        movq    -16(%rbp), %rax
        movq    %rdx, 8(%rax)
        movq    -16(%rbp), %rax
        movq    8(%rax), %rsi
        movl    -28(%rbp), %ecx
        movl    $1717986919, %edx
        movl    %ecx, %eax
        imull   %edx
        sarl    $2, %edx
        movl    %ecx, %eax
        sarl    $31, %eax
        subl    %eax, %edx
        movl    %edx, %eax
        sall    $2, %eax
        addl    %edx, %eax
        addl    %eax, %eax
        subl    %eax, %ecx
        movl    %ecx, %edx
        movl    %edx, (%rsi)
        movq    -16(%rbp), %rax
        movq    8(%rax), %rax
        movq    $0, 8(%rax)
        movl    -28(%rbp), %ecx
        movl    $1717986919, %edx
        movl    %ecx, %eax
        imull   %edx
        sarl    $2, %edx
        movl    %ecx, %eax
        sarl    $31, %eax
        subl    %eax, %edx
        movl    %edx, %eax
        movl    %eax, -4(%rbp)
        movq    -40(%rbp), %rax
        movq    8(%rax), %rax
        movq    %rax, -40(%rbp)
        movq    -48(%rbp), %rax
        movq    8(%rax), %rax
        movq    %rax, -48(%rbp)
        movq    -16(%rbp), %rax
        movq    8(%rax), %rax
        movq    %rax, -16(%rbp)
.L2:
        movq    -40(%rbp), %rax
        movq    8(%rax), %rax
        testq   %rax, %rax
        je      .L5
        movq    -48(%rbp), %rax
        movq    8(%rax), %rax
        testq   %rax, %rax
        jne     .L4
        jmp     .L5
.L6:
        movq    -40(%rbp), %rax
        movq    8(%rax), %rax
        movl    (%rax), %edx
        movl    -4(%rbp), %eax
        addl    %edx, %eax
        movl    %eax, -28(%rbp)
        movl    $16, %edi
        call    malloc
        movq    %rax, %rdx
        movq    -16(%rbp), %rax
        movq    %rdx, 8(%rax)
        movq    -16(%rbp), %rax
        movq    8(%rax), %rsi
        movl    -28(%rbp), %ecx
        movl    $1717986919, %edx
        movl    %ecx, %eax
        imull   %edx
        sarl    $2, %edx
        movl    %ecx, %eax
        sarl    $31, %eax
        subl    %eax, %edx
        movl    %edx, %eax
        sall    $2, %eax
        addl    %edx, %eax
        addl    %eax, %eax
        subl    %eax, %ecx
        movl    %ecx, %edx
        movl    %edx, (%rsi)
        movq    -16(%rbp), %rax
        movq    8(%rax), %rax
        movq    $0, 8(%rax)
        movl    -28(%rbp), %ecx
        movl    $1717986919, %edx
        movl    %ecx, %eax
        imull   %edx
        sarl    $2, %edx
        movl    %ecx, %eax
        sarl    $31, %eax
        subl    %eax, %edx
        movl    %edx, %eax
        movl    %eax, -4(%rbp)
        movq    -40(%rbp), %rax
        movq    8(%rax), %rax
        movq    %rax, -40(%rbp)
        movq    -16(%rbp), %rax
        movq    8(%rax), %rax
        movq    %rax, -16(%rbp)
.L5:
        movq    -40(%rbp), %rax
        movq    8(%rax), %rax
        testq   %rax, %rax
        jne     .L6
        jmp     .L7
.L8:
        movq    -48(%rbp), %rax
        movq    8(%rax), %rax
        movl    (%rax), %edx
        movl    -4(%rbp), %eax
        addl    %edx, %eax
        movl    %eax, -28(%rbp)
        movl    $16, %edi
        call    malloc
        movq    %rax, %rdx
        movq    -16(%rbp), %rax
        movq    %rdx, 8(%rax)
        movq    -16(%rbp), %rax
        movq    8(%rax), %rsi
        movl    -28(%rbp), %ecx
        movl    $1717986919, %edx
        movl    %ecx, %eax
        imull   %edx
        sarl    $2, %edx
        movl    %ecx, %eax
        sarl    $31, %eax
        subl    %eax, %edx
        movl    %edx, %eax
        sall    $2, %eax
        addl    %edx, %eax
        addl    %eax, %eax
        subl    %eax, %ecx
        movl    %ecx, %edx
        movl    %edx, (%rsi)
        movq    -16(%rbp), %rax
        movq    8(%rax), %rax
        movq    $0, 8(%rax)
        movl    -28(%rbp), %ecx
        movl    $1717986919, %edx
        movl    %ecx, %eax
        imull   %edx
        sarl    $2, %edx
        movl    %ecx, %eax
        sarl    $31, %eax
        subl    %eax, %edx
        movl    %edx, %eax
        movl    %eax, -4(%rbp)
        movq    -48(%rbp), %rax
        movq    8(%rax), %rax
        movq    %rax, -48(%rbp)
        movq    -16(%rbp), %rax
        movq    8(%rax), %rax
        movq    %rax, -16(%rbp)
.L7:
        movq    -48(%rbp), %rax
        movq    8(%rax), %rax
        testq   %rax, %rax
        jne     .L8
        cmpl    $0, -4(%rbp)
        je      .L9
        movl    $16, %edi
        call    malloc
        movq    %rax, %rdx
        movq    -16(%rbp), %rax
        movq    %rdx, 8(%rax)
        movq    -16(%rbp), %rax
        movq    8(%rax), %rax
        movl    -4(%rbp), %edx
        movl    %edx, (%rax)
        movq    -16(%rbp), %rax
        movq    8(%rax), %rax
        movq    $0, 8(%rax)
.L9:
        movq    -24(%rbp), %rax
        leave
        ret
