func_1:
        pushq   %rbp
        movq    %rsp, %rbp
        movl    %edi, -20(%rbp)
        cmpl    $0, -20(%rbp)
        jne     .L2
        movl    $1, %eax
        jmp     .L3
.L2:
        movl    $0, -4(%rbp)
        jmp     .L4
.L5:
        movl    -20(%rbp), %ecx
        movl    $1717986919, %edx
        movl    %ecx, %eax
        imull   %edx
        sarl    $2, %edx
        movl    %ecx, %eax
        sarl    $31, %eax
        subl    %eax, %edx
        movl    %edx, %eax
        movl    %eax, -20(%rbp)
        addl    $1, -4(%rbp)
.L4:
        cmpl    $0, -20(%rbp)
        jg      .L5
        movl    -4(%rbp), %eax
.L3:
        popq    %rbp
        ret
func_2:
        pushq   %rbp
        movq    %rsp, %rbp
        subq    $64, %rsp
        movq    %rdi, -56(%rbp)
        movq    %rsi, -64(%rbp)
        movl    $132, %edi
        call    malloc
        movq    %rax, -24(%rbp)
        movl    $0, -4(%rbp)
        jmp     .L7
.L8:
        movl    -4(%rbp), %eax
        movslq  %eax, %rdx
        movq    %rdx, %rax
        addq    %rax, %rax
        addq    %rdx, %rax
        salq    $2, %rax
        movq    %rax, %rdx
        movq    -24(%rbp), %rax
        addq    %rdx, %rax
        movl    $0, 4(%rax)
        movl    -4(%rbp), %eax
        movslq  %eax, %rdx
        movq    %rdx, %rax
        addq    %rax, %rax
        addq    %rdx, %rax
        salq    $2, %rax
        movq    %rax, %rdx
        movq    -24(%rbp), %rax
        addq    %rdx, %rax
        movl    $-1, 8(%rax)
        addl    $1, -4(%rbp)
.L7:
        cmpl    $10, -4(%rbp)
        jle     .L8
        movl    $0, -4(%rbp)
        jmp     .L9
.L10:
        movl    -4(%rbp), %eax
        movslq  %eax, %rdx
        movq    -56(%rbp), %rax
        addq    %rdx, %rax
        movzbl  (%rax), %eax
        movsbl  %al, %eax
        subl    $48, %eax
        movl    %eax, -28(%rbp)
        movl    -4(%rbp), %eax
        movslq  %eax, %rdx
        movq    -56(%rbp), %rax
        leaq    (%rdx,%rax), %rcx
        movl    -28(%rbp), %eax
        movslq  %eax, %rdx
        movq    %rdx, %rax
        addq    %rax, %rax
        addq    %rdx, %rax
        salq    $2, %rax
        movq    %rax, %rdx
        movq    -24(%rbp), %rax
        addq    %rax, %rdx
        movzbl  (%rcx), %eax
        movb    %al, (%rdx)
        movl    -28(%rbp), %eax
        movslq  %eax, %rdx
        movq    %rdx, %rax
        addq    %rax, %rax
        addq    %rdx, %rax
        salq    $2, %rax
        movq    %rax, %rdx
        movq    -24(%rbp), %rax
        addq    %rax, %rdx
        movl    -4(%rbp), %eax
        movl    %eax, 8(%rdx)
        movl    -28(%rbp), %eax
        movslq  %eax, %rdx
        movq    %rdx, %rax
        addq    %rax, %rax
        addq    %rdx, %rax
        salq    $2, %rax
        movq    %rax, %rdx
        movq    -24(%rbp), %rax
        addq    %rdx, %rax
        movl    4(%rax), %edx
        addl    $1, %edx
        movl    %edx, 4(%rax)
        addl    $1, -4(%rbp)
.L9:
        movl    -4(%rbp), %eax
        movslq  %eax, %rdx
        movq    -56(%rbp), %rax
        addq    %rdx, %rax
        movzbl  (%rax), %eax
        testb   %al, %al
        jne     .L10
        movl    $0, -12(%rbp)
        movl    -12(%rbp), %eax
        movl    %eax, -8(%rbp)
        movl    $0, -4(%rbp)
        jmp     .L11
.L16:
        movl    -4(%rbp), %eax
        movslq  %eax, %rdx
        movq    -64(%rbp), %rax
        addq    %rdx, %rax
        movzbl  (%rax), %eax
        movsbl  %al, %eax
        subl    $48, %eax
        movl    %eax, -32(%rbp)
        movl    -32(%rbp), %eax
        movslq  %eax, %rdx
        movq    %rdx, %rax
        addq    %rax, %rax
        addq    %rdx, %rax
        salq    $2, %rax
        movq    %rax, %rdx
        movq    -24(%rbp), %rax
        addq    %rdx, %rax
        movl    8(%rax), %eax
        testl   %eax, %eax
        js      .L12
        movl    -4(%rbp), %eax
        movslq  %eax, %rdx
        movq    -64(%rbp), %rax
        addq    %rdx, %rax
        movzbl  (%rax), %edx
        movl    -4(%rbp), %eax
        movslq  %eax, %rcx
        movq    -56(%rbp), %rax
        addq    %rcx, %rax
        movzbl  (%rax), %eax
        cmpb    %al, %dl
        jne     .L13
        addl    $1, -8(%rbp)
        movl    -32(%rbp), %eax
        movslq  %eax, %rdx
        movq    %rdx, %rax
        addq    %rax, %rax
        addq    %rdx, %rax
        salq    $2, %rax
        movq    %rax, %rdx
        movq    -24(%rbp), %rax
        addq    %rdx, %rax
        movl    4(%rax), %eax
        testl   %eax, %eax
        jg      .L15
        subl    $1, -12(%rbp)
        jmp     .L15
.L13:
        movl    -32(%rbp), %eax
        movslq  %eax, %rdx
        movq    %rdx, %rax
        addq    %rax, %rax
        addq    %rdx, %rax
        salq    $2, %rax
        movq    %rax, %rdx
        movq    -24(%rbp), %rax
        addq    %rdx, %rax
        movl    4(%rax), %eax
        testl   %eax, %eax
        jle     .L15
        addl    $1, -12(%rbp)
.L15:
        movl    -32(%rbp), %eax
        movslq  %eax, %rdx
        movq    %rdx, %rax
        addq    %rax, %rax
        addq    %rdx, %rax
        salq    $2, %rax
        movq    %rax, %rdx
        movq    -24(%rbp), %rax
        addq    %rdx, %rax
        movl    4(%rax), %edx
        subl    $1, %edx
        movl    %edx, 4(%rax)
.L12:
        addl    $1, -4(%rbp)
.L11:
        movl    -4(%rbp), %eax
        movslq  %eax, %rdx
        movq    -64(%rbp), %rax
        addq    %rdx, %rax
        movzbl  (%rax), %eax
        testb   %al, %al
        jne     .L16
        movq    -24(%rbp), %rax
        movq    %rax, %rdi
        call    free
        movl    -8(%rbp), %eax
        movl    %eax, %edi
        call    func_1
        movl    %eax, -36(%rbp)
        movl    -12(%rbp), %eax
        movl    %eax, %edi
        call    func_1
        movl    %eax, -40(%rbp)
        movl    -36(%rbp), %eax
        leal    3(%rax), %edx
        movl    -40(%rbp), %eax
        addl    %edx, %eax
        cltq
        movl    $1, %esi
        movq    %rax, %rdi
        call    calloc
        movq    %rax, -48(%rbp)
        movq    -48(%rbp), %rax
        leave
        ret
