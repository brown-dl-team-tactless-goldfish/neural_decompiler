func_1:
        pushq   %rbp
        movq    %rsp, %rbp
        subq    $80, %rsp
        movq    %rdi, -56(%rbp)
        movl    %esi, -60(%rbp)
        movl    %edx, -64(%rbp)
        movq    %rcx, -72(%rbp)
        movl    -60(%rbp), %eax
        subl    $1, %eax
        movl    %eax, -20(%rbp)
        movl    -20(%rbp), %eax
        movl    %eax, -4(%rbp)
        jmp     .L2
.L4:
        movl    -64(%rbp), %ecx
        movl    $1717986919, %edx
        movl    %ecx, %eax
        imull   %edx
        sarl    $2, %edx
        movl    %ecx, %eax
        sarl    $31, %eax
        subl    %eax, %edx
        movl    %edx, %eax
        sall    $2, %eax
        addl    %edx, %eax
        addl    %eax, %eax
        subl    %eax, %ecx
        movl    %ecx, %eax
        movl    %eax, -24(%rbp)
        movl    -4(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rdx
        movq    -56(%rbp), %rax
        addq    %rdx, %rax
        movl    (%rax), %ecx
        movl    -4(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rdx
        movq    -56(%rbp), %rax
        addq    %rdx, %rax
        movl    -24(%rbp), %edx
        addl    %ecx, %edx
        movl    %edx, (%rax)
        movl    -24(%rbp), %eax
        subl    %eax, -64(%rbp)
        movl    -64(%rbp), %ecx
        movl    $1717986919, %edx
        movl    %ecx, %eax
        imull   %edx
        sarl    $2, %edx
        movl    %ecx, %eax
        sarl    $31, %eax
        subl    %eax, %edx
        movl    %edx, %eax
        movl    %eax, -64(%rbp)
        movl    -4(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rdx
        movq    -56(%rbp), %rax
        addq    %rdx, %rax
        movl    (%rax), %eax
        cmpl    $9, %eax
        jle     .L3
        movl    -4(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rdx
        movq    -56(%rbp), %rax
        addq    %rdx, %rax
        movl    (%rax), %edx
        movl    -4(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rcx
        movq    -56(%rbp), %rax
        addq    %rcx, %rax
        subl    $10, %edx
        movl    %edx, (%rax)
        movl    -4(%rbp), %eax
        cltq
        salq    $2, %rax
        leaq    -4(%rax), %rdx
        movq    -56(%rbp), %rax
        addq    %rdx, %rax
        movl    (%rax), %edx
        movl    -4(%rbp), %eax
        cltq
        salq    $2, %rax
        leaq    -4(%rax), %rcx
        movq    -56(%rbp), %rax
        addq    %rcx, %rax
        addl    $1, %edx
        movl    %edx, (%rax)
.L3:
        subl    $1, -4(%rbp)
.L2:
        cmpl    $0, -4(%rbp)
        jg      .L4
        movq    -56(%rbp), %rax
        movl    (%rax), %edx
        movl    -64(%rbp), %eax
        addl    %eax, %edx
        movq    -56(%rbp), %rax
        movl    %edx, (%rax)
        movq    -72(%rbp), %rax
        movl    -60(%rbp), %edx
        movl    %edx, (%rax)
        movq    -56(%rbp), %rax
        movl    (%rax), %eax
        cmpl    $9, %eax
        jle     .L5
        movl    $80088, %edi
        call    malloc
        movq    %rax, -32(%rbp)
        movq    -32(%rbp), %rax
        movl    $80088, %edx
        movl    $0, %esi
        movq    %rax, %rdi
        call    memset
        movq    -56(%rbp), %rax
        movl    (%rax), %eax
        movl    %eax, -8(%rbp)
        movl    $0, -12(%rbp)
        jmp     .L6
.L7:
        movl    -8(%rbp), %ecx
        movl    $1717986919, %edx
        movl    %ecx, %eax
        imull   %edx
        sarl    $2, %edx
        movl    %ecx, %eax
        sarl    $31, %eax
        subl    %eax, %edx
        movl    %edx, %eax
        sall    $2, %eax
        addl    %edx, %eax
        addl    %eax, %eax
        subl    %eax, %ecx
        movl    %ecx, %eax
        movl    %eax, -36(%rbp)
        movl    -12(%rbp), %eax
        leal    1(%rax), %edx
        movl    %edx, -12(%rbp)
        cltq
        leaq    0(,%rax,4), %rdx
        movq    -32(%rbp), %rax
        addq    %rax, %rdx
        movl    -36(%rbp), %eax
        movl    %eax, (%rdx)
        movl    -36(%rbp), %eax
        subl    %eax, -8(%rbp)
        movl    -8(%rbp), %ecx
        movl    $1717986919, %edx
        movl    %ecx, %eax
        imull   %edx
        sarl    $2, %edx
        movl    %ecx, %eax
        sarl    $31, %eax
        subl    %eax, %edx
        movl    %edx, %eax
        movl    %eax, -8(%rbp)
.L6:
        cmpl    $0, -8(%rbp)
        jg      .L7
        movl    $0, -16(%rbp)
        jmp     .L8
.L9:
        movl    -16(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rdx
        movq    -32(%rbp), %rax
        addq    %rdx, %rax
        movl    (%rax), %eax
        movl    %eax, -40(%rbp)
        movl    -12(%rbp), %eax
        subl    -16(%rbp), %eax
        cltq
        salq    $2, %rax
        leaq    -4(%rax), %rdx
        movq    -32(%rbp), %rax
        addq    %rdx, %rax
        movl    -16(%rbp), %edx
        movslq  %edx, %rdx
        leaq    0(,%rdx,4), %rcx
        movq    -32(%rbp), %rdx
        addq    %rcx, %rdx
        movl    (%rax), %eax
        movl    %eax, (%rdx)
        movl    -12(%rbp), %eax
        subl    -16(%rbp), %eax
        cltq
        salq    $2, %rax
        leaq    -4(%rax), %rdx
        movq    -32(%rbp), %rax
        addq    %rax, %rdx
        movl    -40(%rbp), %eax
        movl    %eax, (%rdx)
        addl    $1, -16(%rbp)
.L8:
        movl    -12(%rbp), %eax
        movl    %eax, %edx
        shrl    $31, %edx
        addl    %edx, %eax
        sarl    %eax
        cmpl    %eax, -16(%rbp)
        jl      .L9
        movl    -60(%rbp), %eax
        subl    $1, %eax
        cltq
        leaq    0(,%rax,4), %rdx
        movq    -56(%rbp), %rax
        leaq    4(%rax), %rcx
        movl    -12(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rsi
        movq    -32(%rbp), %rax
        addq    %rsi, %rax
        movq    %rcx, %rsi
        movq    %rax, %rdi
        call    memcpy
        movl    -12(%rbp), %edx
        movl    -60(%rbp), %eax
        addl    %edx, %eax
        leal    -1(%rax), %edx
        movq    -72(%rbp), %rax
        movl    %edx, (%rax)
        movq    -32(%rbp), %rax
        jmp     .L10
.L5:
        movq    -56(%rbp), %rax
.L10:
        leave
        ret
