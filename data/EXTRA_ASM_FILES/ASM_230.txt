kthSmallest0:
        pushq   %rbp
        movq    %rsp, %rbp
        movq    %rdi, -40(%rbp)
        movl    %esi, -44(%rbp)
        cmpq    $0, -40(%rbp)
        je      .L2
        cmpl    $0, -44(%rbp)
        jne     .L3
.L2:
        movl    $-1, %eax
        jmp     .L4
.L3:
        movq    -40(%rbp), %rax
        movq    %rax, -8(%rbp)
        movq    $0, -16(%rbp)
        movl    $0, -20(%rbp)
        movl    $-1, -24(%rbp)
        jmp     .L5
.L15:
        movq    -8(%rbp), %rax
        movq    8(%rax), %rax
        testq   %rax, %rax
        je      .L6
        movq    -8(%rbp), %rax
        addq    $8, %rax
        movq    %rax, -16(%rbp)
.L13:
        movq    -16(%rbp), %rax
        movq    (%rax), %rax
        testq   %rax, %rax
        jne     .L7
        movl    -20(%rbp), %eax
        cmpl    -44(%rbp), %eax
        jl      .L8
        movq    -8(%rbp), %rax
        movq    16(%rax), %rax
        movq    %rax, -8(%rbp)
        jmp     .L5
.L8:
        movq    -16(%rbp), %rax
        movq    -8(%rbp), %rdx
        movq    %rdx, (%rax)
        movq    -8(%rbp), %rax
        movq    8(%rax), %rax
        movq    %rax, -8(%rbp)
        jmp     .L5
.L7:
        movq    -16(%rbp), %rax
        movq    (%rax), %rax
        cmpq    %rax, -8(%rbp)
        jne     .L11
        addl    $1, -20(%rbp)
        movl    -20(%rbp), %eax
        cmpl    -44(%rbp), %eax
        jne     .L12
        movq    -8(%rbp), %rax
        movl    (%rax), %eax
        movl    %eax, -24(%rbp)
.L12:
        movq    -16(%rbp), %rax
        movq    $0, (%rax)
        movq    -8(%rbp), %rax
        movq    16(%rax), %rax
        movq    %rax, -8(%rbp)
        jmp     .L5
.L11:
        movq    -16(%rbp), %rax
        movq    (%rax), %rax
        addq    $16, %rax
        movq    %rax, -16(%rbp)
        jmp     .L13
.L6:
        addl    $1, -20(%rbp)
        movl    -20(%rbp), %eax
        cmpl    -44(%rbp), %eax
        jne     .L14
        movq    -8(%rbp), %rax
        movl    (%rax), %eax
        movl    %eax, -24(%rbp)
.L14:
        movq    -8(%rbp), %rax
        movq    16(%rax), %rax
        movq    %rax, -8(%rbp)
.L5:
        cmpq    $0, -8(%rbp)
        jne     .L15
        movl    -24(%rbp), %eax
.L4:
        popq    %rbp
        ret
getCount:
        pushq   %rbp
        movq    %rsp, %rbp
        pushq   %rbx
        subq    $24, %rsp
        movq    %rdi, -24(%rbp)
        cmpq    $0, -24(%rbp)
        jne     .L17
        movl    $0, %eax
        jmp     .L18
.L17:
        movq    -24(%rbp), %rax
        movq    8(%rax), %rax
        movq    %rax, %rdi
        call    getCount
        movl    %eax, %ebx
        movq    -24(%rbp), %rax
        movq    16(%rax), %rax
        movq    %rax, %rdi
        call    getCount
        addl    %ebx, %eax
        addl    $1, %eax
.L18:
        addq    $24, %rsp
        popq    %rbx
        popq    %rbp
        ret
kthSmallest1:
        pushq   %rbp
        movq    %rsp, %rbp
        subq    $32, %rsp
        movq    %rdi, -24(%rbp)
        movl    %esi, -28(%rbp)
        cmpq    $0, -24(%rbp)
        je      .L20
        cmpl    $0, -28(%rbp)
        jne     .L21
.L20:
        movl    $-1, %eax
        jmp     .L22
.L21:
        movq    -24(%rbp), %rax
        movq    8(%rax), %rax
        movq    %rax, %rdi
        call    getCount
        movl    %eax, -4(%rbp)
        movl    -28(%rbp), %eax
        subl    $1, %eax
        cmpl    %eax, -4(%rbp)
        jne     .L23
        movq    -24(%rbp), %rax
        movl    (%rax), %eax
        jmp     .L22
.L23:
        movl    -4(%rbp), %eax
        cmpl    -28(%rbp), %eax
        jge     .L24
        movl    -28(%rbp), %eax
        subl    -4(%rbp), %eax
        leal    -1(%rax), %edx
        movq    -24(%rbp), %rax
        movq    16(%rax), %rax
        movl    %edx, %esi
        movq    %rax, %rdi
        call    kthSmallest1
        jmp     .L22
.L24:
        movq    -24(%rbp), %rax
        movq    8(%rax), %rax
        movl    -28(%rbp), %edx
        movl    %edx, %esi
        movq    %rax, %rdi
        call    kthSmallest1
.L22:
        leave
        ret
findHelper:
        pushq   %rbp
        movq    %rsp, %rbp
        subq    $32, %rsp
        movq    %rdi, -24(%rbp)
        movq    %rsi, -32(%rbp)
        cmpq    $0, -24(%rbp)
        je      .L26
        movq    -32(%rbp), %rax
        movl    (%rax), %eax
        testl   %eax, %eax
        jne     .L27
.L26:
        movl    $-1, %eax
        jmp     .L28
.L27:
        movq    -24(%rbp), %rax
        movq    8(%rax), %rax
        movq    -32(%rbp), %rdx
        movq    %rdx, %rsi
        movq    %rax, %rdi
        call    findHelper
        movl    %eax, -4(%rbp)
        movq    -32(%rbp), %rax
        movl    (%rax), %eax
        testl   %eax, %eax
        jne     .L29
        movl    -4(%rbp), %eax
        jmp     .L28
.L29:
        movq    -32(%rbp), %rax
        movl    (%rax), %eax
        leal    -1(%rax), %edx
        movq    -32(%rbp), %rax
        movl    %edx, (%rax)
        movq    -32(%rbp), %rax
        movl    (%rax), %eax
        testl   %eax, %eax
        jne     .L30
        movq    -24(%rbp), %rax
        movl    (%rax), %eax
        jmp     .L28
.L30:
        movq    -24(%rbp), %rax
        movq    16(%rax), %rax
        movq    -32(%rbp), %rdx
        movq    %rdx, %rsi
        movq    %rax, %rdi
        call    findHelper
.L28:
        leave
        ret
kthSmallest:
        pushq   %rbp
        movq    %rsp, %rbp
        subq    $16, %rsp
        movq    %rdi, -8(%rbp)
        movl    %esi, -12(%rbp)
        leaq    -12(%rbp), %rdx
        movq    -8(%rbp), %rax
        movq    %rdx, %rsi
        movq    %rax, %rdi
        call    findHelper
        leave
        ret
main:
        pushq   %rbp
        movq    %rsp, %rbp
        subq    $32, %rsp
        movl    $24, %esi
        movl    $9, %edi
        call    calloc
        movq    %rax, -16(%rbp)
        movq    -16(%rbp), %rax
        movq    %rax, -24(%rbp)
        movq    -24(%rbp), %rax
        movl    $6, (%rax)
        movq    -16(%rbp), %rax
        leaq    24(%rax), %rdx
        movq    -24(%rbp), %rax
        movq    %rdx, 8(%rax)
        movq    -16(%rbp), %rax
        leaq    48(%rax), %rdx
        movq    -24(%rbp), %rax
        movq    %rdx, 16(%rax)
        movq    -24(%rbp), %rax
        movq    8(%rax), %rax
        movq    %rax, -24(%rbp)
        movq    -24(%rbp), %rax
        movl    $2, (%rax)
        movq    -16(%rbp), %rax
        leaq    72(%rax), %rdx
        movq    -24(%rbp), %rax
        movq    %rdx, 8(%rax)
        movq    -16(%rbp), %rax
        leaq    96(%rax), %rdx
        movq    -24(%rbp), %rax
        movq    %rdx, 16(%rax)
        movq    -24(%rbp), %rax
        movq    8(%rax), %rax
        movq    %rax, -24(%rbp)
        movq    -24(%rbp), %rax
        movl    $1, (%rax)
        movq    -16(%rbp), %rax
        addq    $96, %rax
        movq    %rax, -24(%rbp)
        movq    -24(%rbp), %rax
        movl    $4, (%rax)
        movq    -16(%rbp), %rax
        leaq    120(%rax), %rdx
        movq    -24(%rbp), %rax
        movq    %rdx, 8(%rax)
        movq    -16(%rbp), %rax
        leaq    144(%rax), %rdx
        movq    -24(%rbp), %rax
        movq    %rdx, 16(%rax)
        movq    -16(%rbp), %rax
        addq    $120, %rax
        movq    %rax, -24(%rbp)
        movq    -24(%rbp), %rax
        movl    $3, (%rax)
        movq    -16(%rbp), %rax
        addq    $144, %rax
        movq    %rax, -24(%rbp)
        movq    -24(%rbp), %rax
        movl    $5, (%rax)
        movq    -16(%rbp), %rax
        addq    $48, %rax
        movq    %rax, -24(%rbp)
        movq    -24(%rbp), %rax
        movl    $7, (%rax)
        movq    -16(%rbp), %rax
        leaq    168(%rax), %rdx
        movq    -24(%rbp), %rax
        movq    %rdx, 16(%rax)
        movq    -24(%rbp), %rax
        movq    16(%rax), %rax
        movq    %rax, -24(%rbp)
        movq    -24(%rbp), %rax
        movl    $9, (%rax)
        movq    -16(%rbp), %rax
        leaq    192(%rax), %rdx
        movq    -24(%rbp), %rax
        movq    %rdx, 8(%rax)
        movq    -24(%rbp), %rax
        movq    8(%rax), %rax
        movq    %rax, -24(%rbp)
        movq    -24(%rbp), %rax
        movl    $8, (%rax)
        movl    $1, -4(%rbp)
        jmp     .L34
.L35:
        addl    $1, -4(%rbp)
.L34:
        cmpl    $9, -4(%rbp)
        jle     .L35
        movl    $0, %eax
        leave
        ret
