cmp:
        pushq   %rbp
        movq    %rsp, %rbp
        movq    %rdi, -8(%rbp)
        movq    %rsi, -16(%rbp)
        movq    -8(%rbp), %rax
        movl    (%rax), %edx
        movq    -16(%rbp), %rax
        movl    (%rax), %eax
        subl    %eax, %edx
        movl    %edx, %eax
        popq    %rbp
        ret
checkArithmeticSubarrays:
        pushq   %rbp
        movq    %rsp, %rbp
        subq    $2080, %rsp
        movq    %rdi, -2040(%rbp)
        movl    %esi, -2044(%rbp)
        movq    %rdx, -2056(%rbp)
        movl    %ecx, -2048(%rbp)
        movq    %r8, -2064(%rbp)
        movl    %r9d, -2068(%rbp)
        movl    -2048(%rbp), %eax
        cltq
        movq    %rax, %rdi
        call    malloc
        movq    %rax, -24(%rbp)
        movl    $0, -4(%rbp)
        jmp     .L4
.L5:
        movl    -4(%rbp), %eax
        movslq  %eax, %rdx
        movq    -24(%rbp), %rax
        addq    %rdx, %rax
        movb    $1, (%rax)
        addl    $1, -4(%rbp)
.L4:
        movl    -4(%rbp), %eax
        cmpl    -2048(%rbp), %eax
        jl      .L5
        movq    16(%rbp), %rax
        movl    -2048(%rbp), %edx
        movl    %edx, (%rax)
        movl    $0, -8(%rbp)
        jmp     .L6
.L11:
        movl    -8(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rdx
        movq    -2064(%rbp), %rax
        addq    %rdx, %rax
        movl    (%rax), %edx
        movl    -8(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rcx
        movq    -2056(%rbp), %rax
        addq    %rcx, %rax
        movl    (%rax), %eax
        subl    %eax, %edx
        movl    %edx, %eax
        addl    $1, %eax
        cltq
        leaq    0(,%rax,4), %rdx
        movl    -8(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rcx
        movq    -2056(%rbp), %rax
        addq    %rcx, %rax
        movl    (%rax), %eax
        cltq
        leaq    0(,%rax,4), %rcx
        movq    -2040(%rbp), %rax
        addq    %rax, %rcx
        leaq    -2032(%rbp), %rax
        movq    %rcx, %rsi
        movq    %rax, %rdi
        call    memcpy
        movl    -8(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rdx
        movq    -2064(%rbp), %rax
        addq    %rdx, %rax
        movl    (%rax), %edx
        movl    -8(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rcx
        movq    -2056(%rbp), %rax
        addq    %rcx, %rax
        movl    (%rax), %eax
        subl    %eax, %edx
        movl    %edx, %eax
        addl    $1, %eax
        movslq  %eax, %rsi
        leaq    -2032(%rbp), %rax
        movl    $cmp, %ecx
        movl    $4, %edx
        movq    %rax, %rdi
        call    qsort
        movl    -2028(%rbp), %edx
        movl    -2032(%rbp), %eax
        subl    %eax, %edx
        movl    %edx, %eax
        movl    %eax, -28(%rbp)
        movl    $0, -12(%rbp)
        jmp     .L7
.L10:
        movl    -12(%rbp), %eax
        addl    $1, %eax
        cltq
        movl    -2032(%rbp,%rax,4), %edx
        movl    -12(%rbp), %eax
        cltq
        movl    -2032(%rbp,%rax,4), %eax
        subl    %eax, %edx
        movl    %edx, %eax
        cmpl    %eax, -28(%rbp)
        je      .L8
        movl    -8(%rbp), %eax
        movslq  %eax, %rdx
        movq    -24(%rbp), %rax
        addq    %rdx, %rax
        movb    $0, (%rax)
        jmp     .L9
.L8:
        addl    $1, -12(%rbp)
.L7:
        movl    -8(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rdx
        movq    -2064(%rbp), %rax
        addq    %rdx, %rax
        movl    (%rax), %edx
        movl    -8(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rcx
        movq    -2056(%rbp), %rax
        addq    %rcx, %rax
        movl    (%rax), %eax
        subl    %eax, %edx
        movl    %edx, %eax
        cmpl    %eax, -12(%rbp)
        jl      .L10
.L9:
        addl    $1, -8(%rbp)
.L6:
        movl    -8(%rbp), %eax
        cmpl    -2048(%rbp), %eax
        jl      .L11
        movq    -24(%rbp), %rax
        leave
        ret
