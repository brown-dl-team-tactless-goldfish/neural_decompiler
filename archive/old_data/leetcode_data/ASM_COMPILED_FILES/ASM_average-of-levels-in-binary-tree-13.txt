func_1:
        pushq   %rbp
        movq    %rsp, %rbp
        addq    $-128, %rsp
        movq    %rdi, -120(%rbp)
        movq    %rsi, -128(%rbp)
        movl    $10, -4(%rbp)
        movl    -4(%rbp), %eax
        cltq
        salq    $3, %rax
        movq    %rax, %rdi
        call    malloc
        movq    %rax, -16(%rbp)
        movl    -4(%rbp), %eax
        cltq
        salq    $2, %rax
        movq    %rax, %rdi
        call    malloc
        movq    %rax, -24(%rbp)
        movl    $0, -28(%rbp)
        movl    $1, -32(%rbp)
        movl    $10, -36(%rbp)
        movl    -36(%rbp), %eax
        cltq
        salq    $3, %rax
        movq    %rax, %rdi
        call    malloc
        movq    %rax, -48(%rbp)
        movl    -36(%rbp), %eax
        cltq
        salq    $2, %rax
        movq    %rax, %rdi
        call    malloc
        movq    %rax, -56(%rbp)
        movl    $-1, -60(%rbp)
        movq    -120(%rbp), %rax
        movq    %rax, -72(%rbp)
        jmp     .L2
.L10:
        movq    -72(%rbp), %rax
        movl    (%rax), %eax
        movl    %eax, -80(%rbp)
        movl    -32(%rbp), %eax
        cmpl    -4(%rbp), %eax
        jle     .L3
        sall    -4(%rbp)
        movl    -4(%rbp), %eax
        cltq
        leaq    0(,%rax,8), %rdx
        movq    -16(%rbp), %rax
        movq    %rdx, %rsi
        movq    %rax, %rdi
        call    realloc
        movq    %rax, -16(%rbp)
        movl    -4(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rdx
        movq    -24(%rbp), %rax
        movq    %rdx, %rsi
        movq    %rax, %rdi
        call    realloc
        movq    %rax, -24(%rbp)
.L3:
        movl    -32(%rbp), %eax
        cmpl    -28(%rbp), %eax
        jle     .L4
        movl    -32(%rbp), %eax
        cltq
        salq    $3, %rax
        leaq    -8(%rax), %rdx
        movq    -16(%rbp), %rax
        addq    %rax, %rdx
        movl    -80(%rbp), %eax
        cltq
        movq    %rax, (%rdx)
        movl    -32(%rbp), %eax
        cltq
        salq    $2, %rax
        leaq    -4(%rax), %rdx
        movq    -24(%rbp), %rax
        addq    %rdx, %rax
        movl    $1, (%rax)
        movl    -32(%rbp), %eax
        movl    %eax, -28(%rbp)
        jmp     .L5
.L4:
        movl    -32(%rbp), %eax
        cltq
        salq    $3, %rax
        leaq    -8(%rax), %rdx
        movq    -16(%rbp), %rax
        addq    %rdx, %rax
        movq    (%rax), %rcx
        movl    -80(%rbp), %eax
        movslq  %eax, %rdx
        movl    -32(%rbp), %eax
        cltq
        salq    $3, %rax
        leaq    -8(%rax), %rsi
        movq    -16(%rbp), %rax
        addq    %rsi, %rax
        addq    %rcx, %rdx
        movq    %rdx, (%rax)
        movl    -32(%rbp), %eax
        cltq
        salq    $2, %rax
        leaq    -4(%rax), %rdx
        movq    -24(%rbp), %rax
        addq    %rdx, %rax
        movl    (%rax), %edx
        movl    -32(%rbp), %eax
        cltq
        salq    $2, %rax
        leaq    -4(%rax), %rcx
        movq    -24(%rbp), %rax
        addq    %rcx, %rax
        addl    $1, %edx
        movl    %edx, (%rax)
.L5:
        movq    -72(%rbp), %rax
        movq    8(%rax), %rax
        movq    %rax, -88(%rbp)
        movq    -72(%rbp), %rax
        movq    16(%rax), %rax
        movq    %rax, -96(%rbp)
        cmpq    $0, -96(%rbp)
        je      .L6
        addl    $1, -60(%rbp)
        movl    -36(%rbp), %eax
        cmpl    -60(%rbp), %eax
        jg      .L7
        sall    -36(%rbp)
        movl    -36(%rbp), %eax
        cltq
        leaq    0(,%rax,8), %rdx
        movq    -48(%rbp), %rax
        movq    %rdx, %rsi
        movq    %rax, %rdi
        call    realloc
        movq    %rax, -48(%rbp)
        movl    -36(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rdx
        movq    -56(%rbp), %rax
        movq    %rdx, %rsi
        movq    %rax, %rdi
        call    realloc
        movq    %rax, -56(%rbp)
.L7:
        movl    -60(%rbp), %eax
        cltq
        leaq    0(,%rax,8), %rdx
        movq    -48(%rbp), %rax
        addq    %rax, %rdx
        movq    -96(%rbp), %rax
        movq    %rax, (%rdx)
        movl    -60(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rdx
        movq    -56(%rbp), %rax
        addq    %rdx, %rax
        movl    -32(%rbp), %edx
        addl    $1, %edx
        movl    %edx, (%rax)
.L6:
        cmpq    $0, -88(%rbp)
        je      .L8
        addl    $1, -32(%rbp)
        movq    -88(%rbp), %rax
        movq    %rax, -72(%rbp)
        jmp     .L2
.L8:
        cmpl    $0, -60(%rbp)
        jns     .L9
        movq    $0, -72(%rbp)
        jmp     .L2
.L9:
        movl    -60(%rbp), %eax
        cltq
        leaq    0(,%rax,8), %rdx
        movq    -48(%rbp), %rax
        addq    %rdx, %rax
        movq    (%rax), %rax
        movq    %rax, -72(%rbp)
        movl    -60(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rdx
        movq    -56(%rbp), %rax
        addq    %rdx, %rax
        movl    (%rax), %eax
        movl    %eax, -32(%rbp)
        subl    $1, -60(%rbp)
.L2:
        cmpq    $0, -72(%rbp)
        jne     .L10
        movl    -28(%rbp), %eax
        cltq
        salq    $3, %rax
        movq    %rax, %rdi
        call    malloc
        movq    %rax, -104(%rbp)
        movl    $0, -76(%rbp)
        jmp     .L11
.L12:
        movl    -76(%rbp), %eax
        cltq
        leaq    0(,%rax,8), %rdx
        movq    -16(%rbp), %rax
        addq    %rdx, %rax
        movq    (%rax), %rax
        cvtsi2sdq       %rax, %xmm0
        movl    -76(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rdx
        movq    -24(%rbp), %rax
        addq    %rdx, %rax
        movl    (%rax), %eax
        cvtsi2sd        %eax, %xmm1
        movl    -76(%rbp), %eax
        cltq
        leaq    0(,%rax,8), %rdx
        movq    -104(%rbp), %rax
        addq    %rdx, %rax
        divsd   %xmm1, %xmm0
        movsd   %xmm0, (%rax)
        addl    $1, -76(%rbp)
.L11:
        movl    -76(%rbp), %eax
        cmpl    -28(%rbp), %eax
        jl      .L12
        movq    -128(%rbp), %rax
        movl    -28(%rbp), %edx
        movl    %edx, (%rax)
        movq    -48(%rbp), %rax
        movq    %rax, %rdi
        call    free
        movq    -56(%rbp), %rax
        movq    %rax, %rdi
        call    free
        movq    -16(%rbp), %rax
        movq    %rax, %rdi
        call    free
        movq    -24(%rbp), %rax
        movq    %rax, %rdi
        call    free
        movq    -104(%rbp), %rax
        leave
        ret
