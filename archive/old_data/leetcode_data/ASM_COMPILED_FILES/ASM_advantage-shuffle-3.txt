func_2:
        pushq   %rbp
        movq    %rsp, %rbp
        movq    %rdi, -8(%rbp)
        movq    %rsi, -16(%rbp)
        movq    -8(%rbp), %rax
        movl    (%rax), %edx
        movq    -16(%rbp), %rax
        movl    (%rax), %eax
        subl    %eax, %edx
        movl    %edx, %eax
        popq    %rbp
        ret
func_1:
        pushq   %rbp
        movq    %rsp, %rbp
        pushq   %r15
        pushq   %r14
        pushq   %r13
        pushq   %r12
        pushq   %rbx
        subq    $88, %rsp
        movq    %rdi, -104(%rbp)
        movl    %esi, -108(%rbp)
        movq    %rdx, -120(%rbp)
        movl    %ecx, -112(%rbp)
        movq    %r8, -128(%rbp)
        movq    %rsp, %rax
        movq    %rax, %rbx
        movl    -108(%rbp), %eax
        cltq
        salq    $2, %rax
        movq    %rax, %rdi
        call    malloc
        movq    %rax, -72(%rbp)
        movl    -112(%rbp), %eax
        movslq  %eax, %rdx
        subq    $1, %rdx
        movq    %rdx, -80(%rbp)
        movslq  %eax, %rdx
        movq    %rdx, %r14
        movl    $0, %r15d
        movslq  %eax, %rdx
        movq    %rdx, %r12
        movl    $0, %r13d
        cltq
        leaq    0(,%rax,8), %rdx
        movl    $16, %eax
        subq    $1, %rax
        addq    %rdx, %rax
        movl    $16, %edi
        movl    $0, %edx
        divq    %rdi
        imulq   $16, %rax, %rax
        subq    %rax, %rsp
        movq    %rsp, %rax
        addq    $3, %rax
        shrq    $2, %rax
        salq    $2, %rax
        movq    %rax, -88(%rbp)
        movl    $0, -60(%rbp)
        jmp     .L4
.L5:
        movl    -60(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rdx
        movq    -120(%rbp), %rax
        addq    %rdx, %rax
        movl    (%rax), %ecx
        movq    -88(%rbp), %rax
        movl    -60(%rbp), %edx
        movslq  %edx, %rdx
        movl    %ecx, (%rax,%rdx,8)
        movq    -88(%rbp), %rax
        movl    -60(%rbp), %edx
        movslq  %edx, %rdx
        movl    -60(%rbp), %ecx
        movl    %ecx, 4(%rax,%rdx,8)
        addl    $1, -60(%rbp)
.L4:
        movl    -60(%rbp), %eax
        cmpl    -112(%rbp), %eax
        jl      .L5
        movl    -112(%rbp), %eax
        movslq  %eax, %rsi
        movq    -104(%rbp), %rax
        movl    $func_2, %ecx
        movl    $4, %edx
        movq    %rax, %rdi
        call    qsort
        movl    -112(%rbp), %eax
        movslq  %eax, %rsi
        movq    -88(%rbp), %rax
        movl    $func_2, %ecx
        movl    $8, %edx
        movq    %rax, %rdi
        call    qsort
        movl    $0, -56(%rbp)
        movl    -112(%rbp), %eax
        subl    $1, %eax
        movl    %eax, -52(%rbp)
        movl    $0, -64(%rbp)
        jmp     .L6
.L9:
        movl    -64(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rdx
        movq    -104(%rbp), %rax
        addq    %rdx, %rax
        movl    (%rax), %ecx
        movq    -88(%rbp), %rax
        movl    -56(%rbp), %edx
        movslq  %edx, %rdx
        movl    (%rax,%rdx,8), %eax
        cmpl    %eax, %ecx
        jle     .L7
        movl    -64(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rdx
        movq    -104(%rbp), %rax
        leaq    (%rdx,%rax), %rcx
        movq    -88(%rbp), %rax
        movl    -56(%rbp), %edx
        movslq  %edx, %rdx
        movl    4(%rax,%rdx,8), %eax
        cltq
        leaq    0(,%rax,4), %rdx
        movq    -72(%rbp), %rax
        addq    %rax, %rdx
        movl    (%rcx), %eax
        movl    %eax, (%rdx)
        addl    $1, -56(%rbp)
        jmp     .L8
.L7:
        movl    -64(%rbp), %eax
        cltq
        leaq    0(,%rax,4), %rdx
        movq    -104(%rbp), %rax
        leaq    (%rdx,%rax), %rcx
        movq    -88(%rbp), %rax
        movl    -52(%rbp), %edx
        movslq  %edx, %rdx
        movl    4(%rax,%rdx,8), %eax
        cltq
        leaq    0(,%rax,4), %rdx
        movq    -72(%rbp), %rax
        addq    %rax, %rdx
        movl    (%rcx), %eax
        movl    %eax, (%rdx)
        subl    $1, -52(%rbp)
.L8:
        addl    $1, -64(%rbp)
.L6:
        movl    -64(%rbp), %eax
        cmpl    -108(%rbp), %eax
        jl      .L9
        movq    -128(%rbp), %rax
        movl    -108(%rbp), %edx
        movl    %edx, (%rax)
        movq    -72(%rbp), %rax
        movq    %rbx, %rsp
        leaq    -40(%rbp), %rsp
        popq    %rbx
        popq    %r12
        popq    %r13
        popq    %r14
        popq    %r15
        popq    %rbp
        ret
